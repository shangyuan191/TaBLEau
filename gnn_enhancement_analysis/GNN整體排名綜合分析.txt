====================================================================================================
GNN整體排名分析 - 綜合對比總結
====================================================================================================

本文檔總結了兩種訓練/驗證/測試比例下，45個GNN變體在所有116個數據集上的整體表現。

====================================================================================================
一、整體排名Top 10 對比
====================================================================================================

大訓練集 (Train/Val/Test = 0.8/0.15/0.05):
----------------------------------------------------------------------------------------------------
排名    模型配置                                           平均排名
----------------------------------------------------------------------------------------------------
1      resnet(gnn_stage=decoding)                      15.78  ⭐ 最佳
2      trompt(gnn_stage=decoding)                      17.91
3      subtab(gnn_stage=start)                         18.45
4      subtab(gnn_stage=columnwise)                    19.03
5      scarf(gnn_stage=materialize)                    19.40
6      scarf(gnn_stage=start)                          19.48
7      subtab(gnn_stage=materialize)                   19.59
8      subtab(gnn_stage=encoding)                      19.68
9      vime(gnn_stage=encoding)                        20.63
10     fttransformer(gnn_stage=encoding)               20.66

小訓練集 (Train/Val/Test = 0.05/0.15/0.8):
----------------------------------------------------------------------------------------------------
排名    模型配置                                           平均排名
----------------------------------------------------------------------------------------------------
1      subtab(gnn_stage=columnwise)                    15.53  ⭐ 最佳
2      subtab(gnn_stage=encoding)                      15.91
3      subtab(gnn_stage=start)                         15.93
4      subtab(gnn_stage=materialize)                   16.20
5      resnet(gnn_stage=decoding)                      16.41
6      vime(gnn_stage=encoding)                        17.72
7      vime(gnn_stage=columnwise)                      18.65
8      trompt(gnn_stage=decoding)                      19.35
9      tabtransformer(gnn_stage=decoding)              19.94
10     tabnet(gnn_stage=decoding)                      20.61

====================================================================================================
二、各模型整體表現對比
====================================================================================================

大訓練集排名 (按模型平均):
----------------------------------------------------------------------------------------------------
1. subtab           20.01  ⭐ 最穩定的模型
2. resnet           20.83
3. vime             21.39
4. trompt           22.70
5. fttransformer    22.90
6. tabtransformer   23.22
7. scarf            24.00
8. tabnet           25.72
9. excelformer      26.23

小訓練集排名 (按模型平均):
----------------------------------------------------------------------------------------------------
1. subtab           17.49  ⭐⭐ 在小訓練集上表現最優
2. vime             20.29
3. resnet           21.39
4. trompt           22.06
5. tabtransformer   23.37
6. fttransformer    23.81
7. tabnet           24.80
8. excelformer      25.46
9. scarf            28.33

====================================================================================================
三、各GNN階段整體表現對比
====================================================================================================

大訓練集排名 (按GNN階段平均):
----------------------------------------------------------------------------------------------------
1. start            22.31  ⭐ 在大訓練集上最佳階段
2. materialize      22.84
3. decoding         22.95
4. encoding         23.19
5. columnwise       23.71

小訓練集排名 (按GNN階段平均):
----------------------------------------------------------------------------------------------------
1. decoding         22.28  ⭐ 在小訓練集上最佳階段
2. start            22.63
3. columnwise       23.22
4. encoding         23.42
5. materialize      23.45

====================================================================================================
四、關鍵發現與洞察
====================================================================================================

1. 最佳模型選擇:
   ✓ subtab 在兩種訓練比例下都表現最佳，尤其在小訓練集上優勢明顯
   ✓ subtab 的四種GNN配置都進入小訓練集Top 4
   ✓ resnet 在大訓練集上的decoding階段排名第一

2. 訓練集大小的影響:
   ✓ 大訓練集: 更適合使用 start 和 materialize 階段
   ✓ 小訓練集: decoding 階段表現更好
   ✓ subtab 在小訓練集上的優勢更加顯著 (17.49 vs 20.01)

3. GNN階段選擇策略:
   ✓ 通用最佳: start 和 decoding 階段在兩種場景下都表現良好
   ✓ 大數據場景: 優先選擇 start → materialize → decoding
   ✓ 小數據場景: 優先選擇 decoding → start → columnwise

4. 模型穩定性分析:
   ✓ 最穩定: subtab (在所有GNN階段都表現良好)
   ✓ 最不穩定: scarf (不同階段表現差異大)
   ✓ tabnet: 在encoding/columnwise階段表現較差，建議使用decoding階段

5. 最佳配置組合推薦:

   大訓練集場景 (0.8/0.15/0.05):
   ────────────────────────────
   第一選擇: resnet + decoding
   第二選擇: trompt + decoding
   第三選擇: subtab + start/columnwise
   
   小訓練集場景 (0.05/0.15/0.8):
   ────────────────────────────
   第一選擇: subtab + columnwise/encoding/start
   第二選擇: resnet + decoding
   第三選擇: vime + encoding/columnwise

====================================================================================================
五、Bottom 10 表現最差配置
====================================================================================================

大訓練集:
----------------------------------------------------------------------------------------------------
36. excelformer(encoding)                  25.30
37. tabnet(encoding)                       25.79
38. excelformer(materialize)               26.27
39. tabnet(columnwise)                     26.61
40. excelformer(decoding)                  27.28
41. excelformer(columnwise)                27.28
42. tabnet(decoding)                       28.16
43. scarf(encoding)                        28.73
44. fttransformer(decoding)                28.79
45. scarf(columnwise)                      29.63  ❌ 最差

小訓練集:
----------------------------------------------------------------------------------------------------
36. fttransformer(decoding)                25.95
37. excelformer(materialize)               26.06
38. excelformer(encoding)                  26.43
39. scarf(decoding)                        26.85
40. tabnet(columnwise)                     27.88
41. tabnet(encoding)                       27.96
42. scarf(materialize)                     28.19
43. scarf(start)                           28.37
44. scarf(columnwise)                      28.89
45. scarf(encoding)                        29.33  ❌ 最差

建議避免的配置:
- scarf 模型的所有GNN階段在兩種場景下都表現較差
- tabnet 的 encoding 和 columnwise 階段應避免使用
- excelformer 整體表現不佳，不建議作為首選

====================================================================================================
六、實用建議
====================================================================================================

1. 快速選型指南:
   
   如果你有充足的訓練數據 (>80%用於訓練):
   → 使用 resnet + decoding 或 trompt + decoding
   
   如果你的訓練數據有限 (<10%用於訓練):
   → 使用 subtab + 任意GNN階段 (優先 columnwise/encoding)
   
   如果你需要最穩定的性能:
   → 使用 subtab 模型，它在所有場景下都表現良好

2. GNN階段選擇:
   
   不確定選哪個階段時:
   → 優先嘗試 start 或 decoding，這兩個階段普遍表現較好
   
   想要最大化性能:
   → 根據訓練集大小選擇：大數據用start，小數據用decoding

3. 需要避免的組合:
   
   ❌ scarf + 任意階段 (整體表現最差)
   ❌ tabnet + encoding/columnwise (這兩個階段表現不佳)
   ❌ excelformer + 任意階段 (整體表現不理想)

====================================================================================================
七、數據支持
====================================================================================================

分析基於:
- 數據集總數: 116個
- 數據集分類: 10種 (按大小、任務類型、特徵類型)
- 競爭模型: 45個GNN變體
- 排名方式: 相對排名 (1-45之間)
- 評估指標: 平均排名 (越小越好)

====================================================================================================
