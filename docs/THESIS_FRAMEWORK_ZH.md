# 碩士論文框架 - ALIGN 研究

## 📋 完整論文結構規劃

---

## 第一章：緒論（Introduction）
**章節目標字數：3,000-4,000 字**

### 1.1 研究背景與動機
- 表格數據的重要性與現實應用場景
- 現有深度學習模型的優劣對比
  - 神經網路模型：擅長捕捉非線性，但需大量標註數據
  - 樹狀模型（XGBoost、CatBoost、LightGBM）：在中小型資料集表現優異
  - 預訓練模型（TabPFN）：利用大規模預訓練知識進行快速適應
- 圖神經網路（GNN）的潛力與在表格學習中的未被充分探索的應用空間

### 1.2 問題定位
- **核心問題一**：如何系統性地評估 GNN 與不同表格模型架構的整合效益？
- **核心問題二**：GNN 在不同模型架構、資料型態、樣本規模下的增益如何變化？
- **核心問題三**：在模型的哪個處理階段插入 GNN 最有效？是否存在普遍適用的最優階段？

### 1.3 研究目標與主要貢獻
- ALIGN（Analyzing the Integration of Graph Networks in Tabular Learning）框架的核心定義
- 預期的研究產出
  - 第一階段：全面比較分析（13,920 次實驗）
  - 第二階段：三項系統性消融實驗
- 學術創新點
  - 首次建立統一的五階段流水線進行跨模型的公平 GNN 插入比較
  - 系統性的規模化評估（116 資料集 × 10 可拆分模型 × 6 階段）
  - 揭示 GNN 增益的關鍵決定因素與邊界條件
- 實務應用價值
  - 為工程師提供「何時使用 GNN」的決策指南
  - 開源框架與完全可重現的實驗設定

### 1.4 論文組織
- 各章節的內容預覽與邏輯關係圖
- 閱讀導引：不同背景讀者的推薦章節組合

---

## 第二章：相關研究（Related Work）
**章節目標字數：4,000-5,000 字**

### 2.1 表格深度學習的進展
- 表格數據學習的發展歷程
- 主要 SOTA 模型綜述
  - Transformer 家族：FT-Transformer、TabTransformer、ExcelFormer
  - 注意力機制模型：TabNet
  - 自監督模型：SCARF、VIME、SubTab
  - 其他創新：Trompt、TabM
- 各類模型的設計原理、適用場景與相互優劣

### 2.2 圖神經網路的理論與應用
- GNN 基礎理論
  - 圖卷積網路（GCN）的消息傳遞機制
  - 各類 GNN 變種（GAT、GIN、GraphSAGE 等）
  - 圖構建策略與相似度度量
- GNN 在結構化/非結構化數據上的應用案例
- 動態圖構建（DGM）與可微分近鄰學習的進展

### 2.3 GNN 與表格模型的既有整合嘗試
- 自含式（self-contained）GNN 表格模型的設計思路
  - **TabGNN**：基於圖的特徵交互
  - **T2G-Former**：Table-to-Graph Transformer 映射
  - **DGM（Differentiable Graph Module）**：動態圖結構學習
  - **LAN-GNN**：自適應鄰接學習
- 既有模型的優勢、局限與未解決的問題
- 為何需要系統性的整合分析而非單點改進

### 2.4 本研究相對於既有工作的創新位置
- **系統性**：從單一模型升級到統一框架下的多模型比較
- **規模性**：116 資料集、多階段、多模型的全面評估
- **方法論性**：統一五階段流水線帶來的科學比較優勢
- **實證性**：大規模實驗結果的統計意義與可重現性
- **指導性**：從「是否有效」升級到「何時有效」的機制理解

---

## 第三章：研究方法（Methodology）
**章節目標字數：6,000-8,000 字**

### 3.1 TaBLEau 框架設計

#### 3.1.1 框架架構與核心特色
- 框架定位：統一的表格數據深度學習基準測試框架
- 核心特色
  - 統一介面：所有模型遵循相同的輸入輸出格式
  - 多樣數據：涵蓋 116 個多維度分類的資料集
  - 一致環境：標準化的資料切分與評估指標
  - 可擴展性：支援動態添加新模型與資料集

#### 3.1.2 資料集組織結構
- 總數與分類維度
  - 資料集規模：小型（<5,000 rows）vs 大型（>5,000 rows）
  - 任務類型：二分類（binclass）、多分類（multiclass）、迴歸（regression）
  - 特徵類型占比：數值主導（numerical）、類別主導（categorical）、混合（balanced）
- 典型路徑與存儲位置
- 標準資料切分策略
  - Few-shot 設定（0.05:0.15:0.80）：模擬標註資料稀缺場景
  - Fully-supervised 設定（0.80:0.15:0.05）：充足訓練數據對照組
- 資料特性與多樣性保證

#### 3.1.3 模型族群分類
- 可拆分模型（10 個）
  - PyTorch Frame 家族（6 個）：ExcelFormer、FT-Transformer、ResNet、TabNet、TabTransformer、Trompt
  - Custom 家族（4 個）：SCARF、SubTab、VIME、TabM
- 參考基線模型（8 個）
  - 樹模型（3 個）：XGBoost、CatBoost、LightGBM
  - 自含式 GNN 模型（4 個）：TabGNN、T2G-Former、DGM、LAN-GNN
  - 預訓練模型（1 個）：TabPFN
- 模型總覽表與擴展規劃

### 3.2 統一的五階段流水線設計

#### 3.2.1 設計理念
- 參考 PyTorch Frame 論文的設計思想
- 跨模型公平比較的必要性
- 階段粒度的選擇（既要精細，又要保持通用性）

#### 3.2.2 五個處理階段的詳細定義

**Stage 0: start（起始點，Dummy Stage）**
- 功能：不對資料做任何處理，標記「在模型最前面插入 GNN」的位置
- 實作意義：允許在資料進入主幹前進行圖結構增強

**Stage 1: materialize（物化階段）**
- 功能：
  - 將 DataFrame 轉換為 TensorFrame 或 DataLoader
  - 類別編碼、缺失值處理、標準化正規化
  - 互信息排序等預處理
- 輸出：結構化的 tensor 表示

**Stage 2: encoding（編碼階段）**
- 功能：
  - 欄位編碼為 token 向量
  - 添加位置編碼
  - 生成初始表徵
- 輸出：tokens `[Batch, Features, Channels]`

**Stage 3: columnwise（列間交互階段）**
- 功能：
  - 在欄位維度進行交互學習
  - 多頭注意力機制等交互方式
  - 捕捉不同欄位間的關係
- 輸出：經交互後的 tokens

**Stage 4: decoding（解碼階段）**
- 功能：
  - 特徵表徵解碼為最終預測
  - 池化、全連接層等操作
  - 輸出 logits 或預測值

#### 3.2.3 階段流程與映射驗證
- 階段流程圖
- 模型特定的階段映射
  - 10 個模型的映射說明文件
  - 如何驗證映射的正確性

### 3.3 GNN 插入策略

#### 3.3.1 核心 GNN 組件設計

**DGM_d（動態圖生成模組）**
- 功能：根據輸入特徵動態構建圖結構
- 構圖策略：k-近鄰（k-NN）、完全連接或混合
- 可微分設計：使用 Gumbel softmax 進行可微分近鄰選擇

**SimpleGCN（圖卷積網路）**
- 多層 GCNConv 堆疊
- 可配置層數、隱藏維度、dropout 等超參數
- 消息傳遞與特徵聚合機制

**殘差融合門（Residual Fusion Gate）**
- 融合 GNN 輸出與原始特徵
- 機制：`output = original + sigmoid(alpha) * gnn_output`
- 可學習參數與穩定訓練

**輔助模組**
- 欄位位置編碼、池化、投影層等

#### 3.3.2 六種 GNN 插入策略詳解

**策略 0: none（無插入，基線）**
- 不含任何 GNN
- 性能基準

**策略 1: start（離線特徵預注入）**
- 執行時機：資料進入主幹前
- 處理流程：維度擴展 → 自注意力 → 池化 → 動態建圖 → GCN → 回寫
- 特點：離線式處理，無需改變模型主幹，需要監督信號

**策略 2: materialize（物化後注入）**
- 執行時機：物化後、編碼前
- 在更結構化的資料上進行圖增強
- 離線式處理

**策略 3: encoding（聯訓：編碼後注入）**
- 執行時機：編碼後、卷積前
- 在 token-level 進行圖結構學習
- 端到端聯合訓練

**策略 4: columnwise（聯訓：卷積後注入）**
- 執行時機：列間交互後、解碼前
- 在高階特徵上進行圖交互
- **實驗中最常帶來增益的階段**

**策略 5: decoding（聯訓：以 GNN 取代解碼器）**
- 執行時機：完全取代解碼階段
- 端到端圖預測
- 架構改動最大

#### 3.3.3 注入風格的統一與關鍵觀察
- Dynamic-Graph + Attention（DGM + Self-Attn）設計的優勢
- vs Static kNN Graph 設計的對比
- 對比式自監督目標與 GNN 的潛在衝突
- 模型學習目標與 GNN inductive bias 的相容性分析

#### 3.3.4 GNN 配置參數
- gnn_hidden_dim、gnn_layers、gnn_dropout 等參數設定
- 超參數選擇的依據
- 階段選擇指引

### 3.4 第一階段實驗設計（全面比較分析）

#### 3.4.1 實驗規模與參數
- 模型數量與覆蓋範圍
- 資料集數量：116 個
- 切分策略：2 種（few-shot vs fully-supervised）
- GNN 階段：6 個
- 總實驗次數計算：10 models × 116 datasets × 2 splits × 6 stages = 13,920 次

#### 3.4.2 比較基線設定

**基線類別 1：自身基線**
- few-shot non-GNN：同模型、同切分、無 GNN
- full-sample non-GNN：對照組

**基線類別 2：樹模型基線**
- XGBoost、CatBoost、LightGBM
- 兩種切分設定下的表現

**基線類別 3：自含式 GNN 基線**
- TabGNN、T2G-Former、DGM、LAN-GNN
- 原生 GNN 設計 vs 插入 GNN 的對比

**基線類別 4：預訓練基線**
- TabPFN：大規模預訓練的強基線

#### 3.4.3 評估指標與比較規則
- 主要指標：AUC（分類）、MAE（迴歸）、平均排名
- 容差定義：1e-3
- 嚴格比較 vs 容差比較的應用場景
- Per-category 分組分析（18 個組合）

#### 3.4.4 輸出結構與分析維度
- Per-model 詳細報告結構
- CSV 表格、Markdown 分析、視覺化圖表

### 3.5 第二階段實驗設計（消融研究）

#### 3.5.1 消融實驗一：訓練樣本量對 GNN 增益的影響

**研究假設**
> GNN injection 在訓練樣本量較少時帶來顯著優勢，但隨樣本增加逐漸減弱。

**實驗設計**
- 資料集選擇：small_datasets + binclass（20 個）
- 訓練比例掃描：16 個點（0.05 到 0.80）
- 隨機種子：20 個（完整）或 5 個（快速驗證）
- 固定驗證集：15%

**預期結果特徵**
- None 基線：單調上升
- GNN 變體：低比例時超越 none，高比例時遞減
- Gain 曲線：columnwise 達最大增益，隨 train_ratio 增加遞減

**統計聚合**
- 聚合邏輯：20 資料集 × N 種子 × 6 階段
- 計算：mean, variance, std

#### 3.5.2 消融實驗二：數值特徵占比對 GNN 增益的影響

**研究假設**
> GNN injection 在數值特徵占比高時效果最佳，類別特徵增多時增益遞減。

**實驗設計**
- 資料集選擇：small_datasets + binclass（20 個，需包含混合特徵）
- 數值占比掃描：6-11 個點（100%, 80%, 60%, ..., 0%）
- 特徵調整策略：動態特徵選擇或多樣資料集挑選
- 固定切分：train=0.05, val=0.15, test=0.80（few-shot）

**預期結果特徵**
- 性能與增益隨數值占比遞減
- 原因分析：歐氏距離與特徵相似度的關聯，類別特徵稀疏性

#### 3.5.3 消融實驗三：資料集大小對 GNN 增益的影響

**研究假設**
> GNN injection 在資料集較小時效果最佳，隨資料集變大增益遞減。

**實驗設計**
- 資料集選擇：large_datasets + binclass（20 個）
- 下采樣比例掃描：10 個點（10%, 20%, ..., 100%）
- 每個子集再套用 few-shot 切分（0.05/0.15/0.80）
- 隨機種子：20 個（完整）或 5 個

**重要說明**
- 無論采樣比例，都在子集上套用 few-shot 5% 的訓練比例
- 這用來檢驗「總樣本量」與「訓練樣本量」的相對影響

**預期結果特徵**
- 采樣 10% 時 GNN 增益最大
- 隨采樣比例增加，增益遞減
- 采樣 100% 時，增益接近 0 或略為負值

#### 3.5.4 統計方法與誤差處理
- 均值、方差、標準差的計算與呈現
- t-test/ANOVA 檢驗
- 誤差棒（error bars）或置信區間（confidence interval）的繪製

---

## 第四章：實驗結果與分析（Results and Analysis）
**章節目標字數：8,000-10,000 字**

### 4.1 第一階段：全面比較分析

#### 4.1.1 整體發現與排名
- 各 GNN 階段的平均性能排序
- Columnwise 的穩定優勢論證
- 少樣本情境下的增益量化

#### 4.1.2 按資料集類別的細粒度分析
- 18 個類別組合的性能對比
- 小型 vs 大型資料集的對比
- 不同任務類型的表現差異
  - 二分類任務中 GNN 的最佳效果
  - 多分類與迴歸任務的減弱趨勢
- 特徵類型的影響分析
  - 數值主導 vs 類別主導的鮮明對比

#### 4.1.3 跨模型敏感度分析
- 10 個模型對 GNN 的反應程度排序
- FT-Transformer、ExcelFormer 的高敏感度原因
- TabNet、SCARF 的中等敏感度
- ResNet、VIME 的低敏感度與不穩定性
- 模型設計特徵與 GNN 相容性的關聯

#### 4.1.4 關鍵統計指標
- 每個模型、每個類別的平均排名表
- 各基線類別的擊敗/平手/輸掉統計

### 4.2 與多類基線的對比分析

#### 4.2.1 vs few-shot 非 GNN 基線
- 定義、容差、比較規則
- 數據與結論

#### 4.2.2 vs 樹模型（XGBoost、CatBoost、LightGBM）
- 樹模型在不同資料型態下的強勢表現
- GNN 插入何時能超越樹模型

#### 4.2.3 vs 自含式 GNN 模型（TabGNN、T2G-Former、DGM、LAN-GNN）
- 關鍵問題：原生 GNN 設計 vs 插入 GNN 策略的優劣
- 位置對齐假說：將 self-contained 模型的 GNN 映射到五階段框架
- 實驗發現：何時插入 GNN 能與或超越原生設計

#### 4.2.4 vs 預訓練基線（TabPFN）
- TabPFN 的少樣本優勢
- GNN 插入能否補充預訓練的不足

### 4.3 第二階段消融實驗結果

#### 4.3.1 消融實驗一：訓練樣本量的影響
- 性能曲線呈現（6 條線、誤差棒）
- 增益曲線呈現與趨勢分析
- 臨界點識別（GNN 增益轉負的 train_ratio）
- 模型間的差異（是否所有模型都遵循相同趨勢）
- 統計顯著性檢驗

#### 4.3.2 消融實驗二：數值特徵占比的影響
- 性能 vs 特徵類型的關係圖表
- 增益隨數值占比遞減的定量分析
- 類別特徵對圖構建的具體影響機制
- 跨模型的一致性檢驗

#### 4.3.3 消融實驗三：資料集大小的影響
- 采樣比例與性能的關係圖表
- 小資料集歸納偏差假說的驗證
- 大資料集中 GNN 冗餘性的定量支持
- 樣本量 vs 資料集大小的相互作用

#### 4.3.4 三項消融的綜合對比
- 三個自變量的相對重要性排序
- 相互作用效應分析
- 對「何時使用 GNN」決策的影響

### 4.4 可視化與直觀呈現
- 性能折線圖（6 條線：all stages）
- 增益曲線圖（5 條線：all non-none stages）
- 誤差棒/陰影置信區間
- 熱力圖：模型 × 資料類別 × 最佳階段
- 箱型圖：性能分佈對比
- 模型敏感度排序圖

---

## 第五章：討論（Discussion）
**章節目標字數：5,000-7,000 字**

### 5.1 主要發現與深層機制分析

#### 5.1.1 Columnwise 為何是最優階段？
- 時機恰當性分析
  - 既充分利用了列間交互後的高階特徵
  - 又保留了 token 維度供解碼層使用
- 特徵質量分析
  - 經過列間交互後的特徵更容易構建有意義的圖結構
- 與其他階段的對比
  - 為何 encoding 次優，decoding 更差
  - 為何 start/materialize 效果不佳

#### 5.1.2 為何 GNN 在小資料、少樣本時更有效？
- 歸納偏差（inductive bias）的作用機制
  - 樣本不足時，對圖結構的假設帶來正則化效應
  - 防止過擬合的直覺理解
- 樣本間相似性結構的信息論論證
  - 少量樣本中的相似性關係更為關鍵
- 與充足樣本的對比
  - 充足數據下，模型已能自主學習相似性

#### 5.1.3 為何數值特徵占比高時效果更好？
- 歐氏距離與特徵相似度的直接關聯
  - 數值特徵提供連續的相似性信號
- 類別編碼後的稀疏性問題
  - One-hot 編碼的維度爆炸
  - 稀疏表示中相似性計算的困難
- 實務意涵：何種資料適合 GNN 增強

### 5.2 GNN 增益的邊界條件與無效情境

#### 5.2.1 大資料集、充足樣本下的失效
- 定量證據：gain 如何隨 train_ratio 或資料大小而變化
- 機制分析：
  - 大樣本足以支撐模型的主幹學習
  - GNN 的結構信息變得冗餘
- 資源效益分析：計算開銷 vs 性能增益

#### 5.2.2 強基線的存在如何削弱 GNN 優勢
- 樹模型在充足樣本下的統治地位
  - 為何樹模型更難被超越
  - 特定資料型態（如類別特徵占多）下的優勢根源
- 預訓練模型（TabPFN）的另一維度超越
  - 預訓練 vs GNN 結構先驗的比較
  - 未來整合預訓練 + GNN 的可能性

### 5.3 模型依賴性與架構相容性分析

#### 5.3.1 為何某些模型對 GNN 更敏感
- FT-Transformer 的高敏感度
  - Transformer 架構的特性
  - Token 表徵的幾何特性
- SCARF 的相容性問題
  - 對比式學習目標與 GNN 的衝突
  - 實例判別性（instance discrimination）與鄰域聚合的張力

#### 5.3.2 模型學習目標與 GNN inductive bias 的相容性
- 重建目標 vs 消息聚合平滑化
- 分類目標 vs 樣本聚集的權衡
- 未來工作：自適應地選擇 GNN 配置以匹配模型目標

### 5.4 GNN 插入 vs 自含式 GNN 設計的戰略對比

#### 5.4.1 位置對齐假說的驗證
- 將自含式 GNN 模型的內部處理對應到五階段框架
- DGM、LAN-GNN 的 GNN 相當於五階段中的哪個階段
- 驗證結果：位置對齐是否能解釋性能差異

#### 5.4.2 混合策略（插入 GNN）相對於原生設計的優勢
- 更高的表達能力：利用既有模型的特徵提取能力
- 更靈活的設計空間：可自由選擇插入位置
- 實驗證據：何時插入 GNN 優於原生設計

#### 5.4.3 實務應用的啟示
- 為不同應用場景選擇合適的策略

### 5.5 研究限制與未來方向

#### 5.5.1 研究的明確限制
- 資料集規模與多樣性邊界
  - 為何選擇 116 個資料集（覆蓋範圍說明）
  - 潛在的代表性偏差
- 模型種類的範圍
  - 10 個可拆分模型是否充分代表（覆蓋樹、Transformer、注意力、自監督等）
  - 後續擴展計劃
- 圖構建策略的簡化假設
  - 為何選擇 k-NN（vs 其他構圖方式）
  - 是否會影響結論的通用性

#### 5.5.2 未來研究機會

**方向一：自適應 GNN 插入**
- 根據資料特性（大小、特徵類型）自動選擇最優階段
- 機器學習元學習（meta-learning）的應用

**方向二：多階段聯合插入**
- 同時在多個階段插入 GNN 的協同效應
- 階段間的相互作用設計

**方向三：擴展應用場景**
- 時序表格數據的 GNN 增強
- 多模態表格（文字 + 數值 + 圖像）的整合
- 不平衡資料集的專項分析

**方向四：圖構建策略創新**
- 可學習的圖結構參數
- 動態圖與靜態圖的權衡
- 領域知識的顯式整合

---

## 第六章：結論（Conclusion）
**章節目標字數：2,000-3,000 字**

### 6.1 研究成果總結

#### 6.1.1 ALIGN 框架的核心貢獻
- 統一的五階段流水線：實現跨異構模型的公平比較
- 大規模系統性評估：116 資料集 × 10 模型 × 6 階段 = 13,920 次實驗
- 量化的增益分析：清晰的「何時有效」決策依據

#### 6.1.2 第一階段：全面比較的發現
- Columnwise 階段最穩定地帶來增益
- 少樣本、小資料、數值特徵時最有利
- 樹模型與 GNN 的適用邊界

#### 6.1.3 第二階段：消融實驗的發現
- 訓練樣本量、數值特徵占比、資料集大小的相對重要性
- 增益遞減的量化模式
- 跨模型一致性的驗證

### 6.2 實務指引與決策流程圖

#### 6.2.1 何時使用 GNN 插入（決策樹）
```
1. 資料集大小 < 5,000 rows？
   YES → 2
   NO → 放棄 GNN
   
2. 訓練樣本量 < 總樣本 20%？
   YES → 3
   NO → 放棄 GNN
   
3. 數值特徵占比 > 50%？
   YES → 4
   NO → 謹慎使用 GNN
   
4. 任務類型為二分類？
   YES → 推薦使用 columnwise 階段 GNN
   NO → 考慮 encoding/decoding 階段
```

#### 6.2.2 最佳的階段選擇建議
- **首選**：columnwise（穩定性最高）
- **次選**：encoding（token-level 增強）
- **備選**：decoding（端到端）
- **避免**：start/materialize（離線處理，效果不穩定）

#### 6.2.3 資源與效益的權衡
- 計算開銷分析（GNN 層數、隱藏維度對速度的影響）
- 性能增益的期望值
- 何時不值得付出額外成本

### 6.3 學術影響與開源貢獻

#### 6.3.1 對表格深度學習社群的啟示
- 打破「GNN 總是有益」的過度樂觀預期
- 系統性理解模型架構、資料特性與 GNN 增益的關係
- 為未來研究奠定量化基準

#### 6.3.2 開源資源與可重現性
- TaBLEau 框架的公開發佈
- 116 個資料集的統一預處理
- 13,920 次實驗的完整結果公開
- 三項消融實驗的腳本與結果

#### 6.3.3 後續工作的建議
- 社群應如何利用本框架進行新研究
- 潛在的擴展與改進方向

---

## 附錄

### 附錄 A：資料集詳細列表
- 116 個資料集的名稱、大小、任務類型、特徵分佈
- 按三維分類的詳細統計表

### 附錄 B：模型架構映射文檔
- 10 個可拆分模型與五階段的詳細對應關係
- 各模型的實現文件位置與關鍵代碼片段

### 附錄 C：完整的實驗結果表
- Per-model 的詳細性能指標（AUC/Accuracy/MAE）
- 各基線的擊敗/平手統計
- 所有 (model, dataset, stage) 組合的結果

### 附錄 D：消融實驗的完整圖表集
- 三項消融的所有 10 個模型的性能與增益圖
- 每個圖包含：折線圖 + 誤差棒 + 統計標註

### 附錄 E：超參數敏感度分析
- GNN 層數對性能的影響
- 隱藏維度與計算成本的權衡
- Dropout 比率的效應

### 附錄 F：實現細節與參考代碼
- GNN 插入的偽代碼
- 關鍵函數的 Python 實現
- 資料聚合與繪圖的工具函數

### 附錄 G：超大規模實驗日誌
- 第一階段（13,920 次）的執行統計
- 第二階段消融實驗的耗時與資源使用報告

---

## 📊 論文結構統計

| 章節 | 目標字數 | 全文占比 | 章節數 |
|------|---------|---------|--------|
| 第一章 緒論 | 3,000-4,000 | 8-10% | 4 |
| 第二章 相關研究 | 4,000-5,000 | 10-12% | 4 |
| 第三章 方法論 | 6,000-8,000 | 15-20% | 5 |
| 第四章 實驗結果 | 8,000-10,000 | 20-25% | 4 |
| 第五章 討論 | 5,000-7,000 | 12-17% | 5 |
| 第六章 結論 | 2,000-3,000 | 5-8% | 3 |
| 附錄 | 3,000-5,000 | 7-12% | 7 |
| **全文總計** | **31,000-42,000** | **100%** | **32-27** |

---

## 🎯 論文撰寫建議

### 邏輯遞進的優勢
- ✅ 從動機 → 方法 → 實驗 → 分析 → 結論的清晰遞進
- ✅ 第一階段的全面性 + 第二階段的深度性相結合
- ✅ 統一框架、系統性分析、新的對比維度

### 重點突出的策略
- 在第四章以清晰的圖表展示核心發現
- 在第五章深入機制分析而非僅敘述現象
- 在第六章提供可操作的實務指引

### 可重現性的保證
- 詳細的方法論（第三章）
- 開源的代碼與資料（TaBLEau）
- 完整的統計報告（附錄）

---

**本論文框架為系統、完整、學術導向的設計，旨在為一篇高品質的碩士論文奠定堅實基礎。**

---

*文件生成日期：2026 年 1 月*
